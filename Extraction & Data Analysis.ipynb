{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Customize Pandas\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Customize Seaborn\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir(os.getcwd() + \"\\HEBBdataDivided\") if \".txt\" in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_occurrences = {i: [0 for j in range(9)] for i in range(12)}\n",
    "correct_opportunities = {i: [0 for j in range(9)] for i in range(12)}\n",
    "\n",
    "minus_occurrences = {i: [0 for j in range(8)] for i in range(12)}\n",
    "minus_opportunities = {i: [0 for j in range(8)] for i in range(12)}\n",
    "\n",
    "plus_occurrences = {i: [0 for j in range(8)] for i in range(12)}\n",
    "plus_opportunities = {i: [0 for j in range(8)] for i in range(12)}\n",
    "\n",
    "correct_slopes = []\n",
    "error_slopes = []\n",
    "\n",
    "repeated = [i for i in range(1, 49) if i % 4 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with open(os.getcwd() + \"\\HEBBdataDivided\\\\\" + file) as f:\n",
    "        correct_count = [0 for i in range(9)]\n",
    "        minus_count = [0 for i in range(8)]\n",
    "        plus_count = [0 for i in range(8)]\n",
    "        for line in f:\n",
    "            splitted = line.strip().split(\" \")\n",
    "            if splitted[0] == \"Clicked\" and int(splitted[1].strip(\"():\")) in repeated:\n",
    "                answers = splitted[2:]\n",
    "                for i in range(9):\n",
    "                    correct_opportunities[correct_count[i]][i] += 1\n",
    "                    if correct[i] == answers[i]:\n",
    "                        correct_occurrences[correct_count[i]][i] += 1\n",
    "                        correct_count[i] += 1\n",
    "                for i in range(8):\n",
    "                    minus_opportunities[minus_count[i]][i] += 1\n",
    "                    plus_opportunities[plus_count[i]][i] += 1\n",
    "                    if correct[i] == answers[i + 1]:\n",
    "                        minus_occurrences[minus_count[i]][i] += 1\n",
    "                        minus_count[i] += 1\n",
    "                    if correct[i + 1] == answers[i]:\n",
    "                        plus_occurrences[plus_count[i]][i] += 1\n",
    "                        plus_count[i] += 1\n",
    "            elif splitted[0] == \"Said\" and int(splitted[1].strip(\"():\")) == 4:\n",
    "                correct = splitted[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"correct.txt\", mode=\"w\") as f:\n",
    "    probabilities = []\n",
    "    f.write(\"\\t\".join([\"Serial_position\"] + [str(i) for i in range(1, 5)]) + \"\\n\")\n",
    "    for i in range(9):\n",
    "        f.write(str(i + 1))\n",
    "        row_probability = []\n",
    "        for j in range(1, 5):\n",
    "            f.write(\"\\t\" + str(correct_occurrences[j][i] / correct_opportunities[j][i]))\n",
    "            # append probabilities for j occurence\n",
    "            row_probability.append(\n",
    "                correct_occurrences[j][i] / correct_opportunities[j][i]\n",
    "            )\n",
    "        f.write(\"\\n\")\n",
    "        # append probabilities for i \"row/serial position\"\n",
    "        probabilities.append(row_probability)\n",
    "    # calculate slope for each \"row/serial position\"\n",
    "    x = [1, 2, 3, 4]\n",
    "    correct_slopes = []\n",
    "    for i in range(0, 9):\n",
    "        slope, intercept = np.polyfit(x, probabilities[i], 1)\n",
    "        correct_slopes.append(slope)\n",
    "        print(\"Correct Slope \" + str(i + 1) + \": \" + str(slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"error.txt\", mode=\"w\") as f:\n",
    "\n",
    "    probabilities = []\n",
    "\n",
    "    f.write(\"\\t\".join([\"Transposition\"] + [str(i) for i in range(1, 5)]) + \"\\n\")\n",
    "    \n",
    "    for i in range(8):\n",
    "        f.write(\"T{} + 1\".format(i + 1))\n",
    "        row_probability = []\n",
    "        for j in range(1, 5):\n",
    "            if plus_opportunities[j][i]:\n",
    "                result = str(plus_occurrences[j][i] / plus_opportunities[j][i])\n",
    "\n",
    "                # append probabilities for j occurence\n",
    "                row_probability.append(\n",
    "                    plus_occurrences[j][i] / plus_opportunities[j][i]\n",
    "                )\n",
    "            else:\n",
    "                result = \"NA\"\n",
    "            f.write(\"\\t\" + result)\n",
    "\n",
    "        # append probabilities for i \"row/transposition\"\n",
    "        probabilities.append(row_probability)\n",
    "        row_probability = []\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"T{} - 1\".format(i + 2))\n",
    "        for j in range(1, 5):\n",
    "            if minus_opportunities[j][i]:\n",
    "                result = str(minus_occurrences[j][i] / minus_opportunities[j][i])\n",
    "                # append probabilities for j occurence\n",
    "                row_probability.append(\n",
    "                    minus_occurrences[j][i] / minus_opportunities[j][i]\n",
    "                )\n",
    "            else:\n",
    "                result = \"NA\"\n",
    "            f.write(\"\\t\" + result)\n",
    "\n",
    "        # append probabilities for i \"row/transposition\"\n",
    "        probabilities.append(row_probability)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # calculate slope for each \"row/serial position\"\n",
    "    for i in range(0, 16):\n",
    "        slope, intercept = np.polyfit(\n",
    "            list(range(1, len(probabilities[i]) + 1)), probabilities[i], 1\n",
    "        )\n",
    "        error_slopes.append(slope)\n",
    "        print(\"Error Slope \" + str(i + 1) + \": \" + str(slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes new file \"correctwslopes.txt\" with slope values\n",
    "with open(\"correct.txt\", \"r\") as src:\n",
    "    with open(\"correctwslopes.txt\", \"w\") as dest:\n",
    "        for i, line in enumerate(src):\n",
    "            if i == 0:\n",
    "                dest.write(\"%s%s\\n\" % (line.rstrip(\"\\n\"), \"\\tSlope\"))\n",
    "            else:\n",
    "                dest.write(\"%s%s\\n\" % (line.rstrip(\"\\n\"), \"\\t\"+str(correct_slopes[i-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes new file \"errorwslopes.txt\" with slope values\n",
    "with open(\"error.txt\", \"r\") as src:\n",
    "    with open(\"errorwslopes.txt\", \"w\") as dest:\n",
    "        for i, line in enumerate(src):\n",
    "            if i == 0:\n",
    "                dest.write(\"%s%s\\n\" % (line.rstrip(\"\\n\"), \"\\tSlope\"))\n",
    "            else:\n",
    "                dest.write(\"%s%s\\n\" % (line.rstrip(\"\\n\"), \"\\t\"+str(error_slopes[i-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read corect.txt as dataframe\n",
    "df_correct = pd.read_csv(\"correct.txt\", sep = \"\\t\")\n",
    "df_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot the DataFrame from wide to long format\n",
    "df_correct_long = df_correct.melt(id_vars=[\"Serial_position\"])\n",
    "df_correct_long[\"label\"] = \"Correct\"\n",
    "df_correct_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read error.txt as dataframe\n",
    "df_error = pd.read_csv(\"error.txt\", sep = \"\\t\")\n",
    "df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpivot the DataFrame from wide to long format\n",
    "df_error_long = df_error.melt(id_vars=[\"Transposition\"])\n",
    "df_error_long[\"label\"] = \"Errors\"\n",
    "df_error_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate df_correct and df_error\n",
    "df_correct_error = pd.concat([df_correct_long, df_error_long], axis=0)\n",
    "df_correct_error = df_correct_error.drop([\"Serial_position\", \"Transposition\"], axis=1)\n",
    "df_correct_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a linear regression of correct slopes \n",
    "df_correct_slopes = pd.Series((df_correct.iloc[:, 1:].mean())).reset_index(drop=True)\n",
    "x1 = df_correct_slopes.index; y1 = df_correct_slopes\n",
    "res1 = stats.linregress(x=x1, y=y1)\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a linear regression of errors slopes \n",
    "df_error_slopes = pd.Series((df_error.iloc[:, 1:].mean())).reset_index(drop=True)\n",
    "x2 = df_error_slopes.index; y2 = df_error_slopes\n",
    "res2 = stats.linregress(x=x2, y=y2)\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 7))\n",
    "\n",
    "# Plot strip plot of both correct answers and errors\n",
    "sns.stripplot(data= df_correct_error, y=\"value\", x=\"variable\", \n",
    "                                      hue=\"label\", jitter=False,\n",
    "                                      palette=[\"chocolate\", \"midnightblue\"],\n",
    "                                      marker=\"s\")\n",
    "\n",
    "# Plot linear regression of correct slopes\n",
    "ax.plot(x1, res1.intercept + res1.slope * x1, 'chocolate', label=\"Average Slope (Correct)\")\n",
    "\n",
    "# Plot linear regression of errors slopes\n",
    "ax.plot(x2, res2.intercept + res2.slope * x2, 'darkblue', label=\"Average Slope (Errors)\")\n",
    "ax.lines[1].set_linestyle(\"--\")\n",
    "\n",
    "# Customize ticks of y axis\n",
    "plt.ylim([0, 1])\n",
    "plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
    "\n",
    "# Customize labels of x axis and y axis\n",
    "plt.xlabel(\"Number of times was previously recalled\")\n",
    "plt.ylabel(\"Probability of recalling an item\")\n",
    "\n",
    "# Customize legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "order = [2, 3, 0, 1]\n",
    "plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order], loc='upper left')\n",
    "\n",
    "plt.margins(0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct[\"Slope\"] = correct_slopes\n",
    "df_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error[\"Slope\"] = error_slopes\n",
    "df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6345758e5d736e732c2a7feeb6de508c9984c306a9009e8a74375b042c9b7f5c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
